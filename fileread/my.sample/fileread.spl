
/*
We have used the FileSource and the FileSink operators in other examples
before. However, this example shows off the following intriguing
features that will become handy. 

a) Automatic deletion of a file after the FileSource reads all the records.
b) Flushing the sink file on demand after writing a certain number of tuples.
c) Ability of the FileSource to move the file once it is done with it.
d) Creating a fresh and new output sink file after writing certain number of tuples.
e) Ability of the FileSource to keep reading from a hot file as new CSV records get written.
*/
namespace my.sample ;

type TweetType = rstring id, rstring location, rstring text ;
// In order to test this application, you have to ensure that two 
// sub-directories "test1", "test2" are present inside this application's directory.
// Then, you have to ensure that all the files in "data" directory are copied to "test1".
//
// To test the hotFile function, you have to keep appending new records
// to the test1/DepartmentRecordsFile using a text editor.
composite fileread
{
	type
		cityData = tuple<rstring city, rstring country, uint32 population,
			uint32 medianAge, uint32 percentageEducated> ;
		employee = tuple<rstring name, uint32 employeeDepartment> ;
		department = tuple<uint32 departmentId, rstring departmentName> ;
	graph
		stream<TweetType> Twitter_out0 = FileSource()
		{
			param
				file : "../test1/tweet.txt" ;
				format : csv ;
				hotFile : true ;
				hasDelayField : false ;
		}

		() as FileSinkTwitter = FileSink(Filter_9_out0)
		{
			param
				file : "../test1/filtertweet.txt" ;
				flush : 2u ;
				format : csv ;
				quoteStrings : false ;
		}

		(stream<TweetType> Filter_9_out0) as Filter_9 = Filter(Twitter_out0 as
			inputStream)
		{
			param
				filter : upper(inputStream.location) in ["UK", "LONDON"] ;
		}

		// End of FileSink3 = FileSink(DepartmentRecord)

}